# Model Configuration
# PM models, Chairman model, and Research providers

# Research Layer
research:
  gemini_deep:
    provider: "gemini"
    model: "gemini-2.5-pro"  # Or appropriate deep research model
    api_key_env: "GEMINI_API_KEY"
    enabled: true

  perplexity_deep:
    provider: "perplexity"
    model: "sonar-pro"  # Or appropriate deep research model
    api_key_env: "PERPLEXITY_API_KEY"
    enabled: true

# PM Layer (Portfolio Managers)
pm_models:
  - id: "pm_gpt51"
    name: "GPT-5.1 PM"
    openrouter_id: "openai/gpt-5.1"
    role: "portfolio_manager"
    enabled: true

  - id: "pm_gemini3"
    name: "Gemini 3.0 Pro PM"
    openrouter_id: "google/gemini-3-pro-preview"
    role: "portfolio_manager"
    enabled: true

  - id: "pm_sonnet45"
    name: "Claude Sonnet 4.5 PM"
    openrouter_id: "anthropic/claude-sonnet-4.5"
    role: "portfolio_manager"
    enabled: true

  - id: "pm_grok4"
    name: "Grok 4 PM"
    openrouter_id: "x-ai/grok-4"
    role: "portfolio_manager"
    enabled: true

# Chairman Layer
chairman:
  id: "chairman_opus"
  name: "Chairman (CIO)"
  openrouter_id: "anthropic/claude-opus-4"  # Or other strong synthesizer model
  role: "chairman"
  enabled: true

# OpenRouter Configuration
openrouter:
  api_key_env: "OPENROUTER_API_KEY"
  api_url: "https://openrouter.ai/api/v1/chat/completions"
  default_timeout: 120.0
  max_retries: 3

# Title Generation (fast, cheap model)
title_generation:
  openrouter_id: "google/gemini-2.5-flash"
  timeout: 30.0

# Prompt Templates
prompts:
  pm_pitch_template: "council/prompts/pm_pitch.j2"
  peer_review_template: "council/prompts/peer_review.j2"
  chairman_template: "council/prompts/chairman.j2"

# JSON Schemas
schemas:
  pm_pitch: "council/schemas/pm_pitch.json"
  peer_review: "council/schemas/peer_review.json"
  chairman_decision: "council/schemas/chairman_decision.json"

# Model-Specific Settings
model_settings:
  # Models that support reasoning tokens
  reasoning_models:
    - "openai/o1-preview"
    - "openai/o1-mini"

  # Models that need special formatting
  special_formatting:
    "x-ai/grok-4":
      max_tokens: 4096
      temperature: 0.7

# Validation Settings
validation:
  # Retry with "fix-json" mode on schema validation failure
  auto_fix_json: true
  max_fix_retries: 2

# Logging
logging:
  log_model_calls: true
  log_raw_responses: true
  log_token_usage: true
